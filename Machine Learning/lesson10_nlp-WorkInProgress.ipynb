{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson10-nlp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Giffy/fast.ai/blob/master/Machine%20Learning/lesson10_nlp-WorkInProgress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXlxQjjYWECI",
        "colab_type": "text"
      },
      "source": [
        "**Important: This notebook will only work with fastai-0.7.x. Do not try to run any fastai-1.x code from this path in the repository because it will load fastai-0.7.x**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAb7XDcxWZf4",
        "colab_type": "text"
      },
      "source": [
        "# Google Colab setup\n",
        "Installs fast.ai 0.7.0 and the required libraries to run the notebook.\n",
        "\n",
        "Also downloads the required datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6_XaaZWWbLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\" Installing FastAI libraries...\")\n",
        "!pip install fastai==0.7.0 > /dev/null\n",
        "print (\"\\n Installing required libraries...\")\n",
        "!pip install torchtext==0.2.3 > /dev/null             #   Corrects torch error, accepts Float32 type\n",
        "!git clone https://github.com/fastai/fastai.git fastai_ml\n",
        "!ln -s fastai_ml/courses/ml1/fastai/ fastai\n",
        "print (\"\\n Downloading dataset...\")\n",
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar xvf aclImdb_v1.tar.gz > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b0QBhfi4n-OB",
        "colab": {}
      },
      "source": [
        "!rm -r /usr/local/cuda-10.0\n",
        "!rm /usr/local/cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eXGdd6WQGoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## More info about cuda : https://developer.nvidia.com/cuda-toolkit-archive\n",
        "## get the download link here:   https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1704&target_type=runfilelocal\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/9.0/secure/Prod/local_installers/cuda_9.0.176_384.81_linux.run?nCmXVI3PIiivGFJ01aX0iGX-Ce9gEayOFLd4MteZ3dBW6O84pTVHaKFKbqyJsaMH6rRU31W6AvoNxD9kehws5Glgu26yBynn0g4Zefw4J8qDJXdtjXu4NH_OJN2NxzIo2vHY-vmKbrnUvNqyiM7cwFafngY1uK7e63wp_kWsi37mzaGarhWYAOHI\n",
        "!mv cuda_9.0.176_384.81_linux.run?nCmXVI3PIiivGFJ01aX0iGX-Ce9gEayOFLd4MteZ3dBW6O84pTVHaKFKbqyJsaMH6rRU31W6AvoNxD9kehws5Glgu26yBynn0g4Zefw4J8qDJXdtjXu4NH_OJN2NxzIo2vHY-vmKbrnUvNqyiM7cwFafngY1uK7e63wp_kWsi37mzaGarhWYAOHI cuda_9.0.176_384.81_linux.run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiwFJSBukxqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo sh cuda_9.0.176_384.81_linux.run --silent --toolkit --override"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoSrBtEsqH4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1d859ac-4aa5-4cb9-9c24-0a7dc08d389e"
      },
      "source": [
        "!ls /usr/local/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin  cuda  cuda-9.0  etc  games  include  lib  man  sbin  share  src  xgboost\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOUwDCOUlG2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 05/2019 update to run in Colab with GPU Tesla T4\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\10/'    \n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "accelerator = 'cpu'\n",
        "version='1.0.1'\n",
        "\n",
        "torch_url=f\"http://download.pytorch.org/whl/{accelerator}/torch-{version}-{platform}-linux_x86_64.whl\"\n",
        "\n",
        "!pip install -U {torch_url} torchvision\n",
        "\n",
        "#pip install torch==0.9.0 -f https://download.pytorch.org/whl/cpu/stable # CPU-only build\n",
        "#pip install torch==1.0.1 -f https://download.pytorch.org/whl/cu80/stable # CUDA 8.0 build\n",
        "#pip install torch==0.3.1 -f https://download.pytorch.org/whl/cu90/stable # CUDA 9.0 build\n",
        "#pip install torch==1.0.1 -f https://download.pytorch.org/whl/cu92/stable # CUDA 9.2 build\n",
        "#pip install torch==1.0.1 -f https://download.pytorch.org/whl/cu100/stable # CUDA 10.0 build"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_C7GphVSGye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-9.0/lib64/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1ZWGtBfWEDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "6500beb2-6d8c-40b3-cd67-2908656386aa"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "from fastai.nlp import *\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0658be626de2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fastai/nlp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtorch_imports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fastai/torch_imports.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLongTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mshufflenetv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msegmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfaster_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmask_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkeypoint_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/detection/faster_rcnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmisc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmisc_nn_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_iou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRoIPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeature_pyramid_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeaturePyramidNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/ops/boxes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: libcudart.so.9.0: cannot open shared object file: No such file or directory",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj80KexNWEFu",
        "colab_type": "text"
      },
      "source": [
        "## IMDB dataset and the sentiment classification task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iZkOYMpWEGG",
        "colab_type": "text"
      },
      "source": [
        "The [large movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/) contains a collection of 50,000 reviews from IMDB. The dataset contains an even number of positive and negative reviews. The authors considered only highly polarized reviews. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. Neutral reviews are not included in the dataset. The dataset is divided into training and test sets. The training set is the same 25,000 labeled reviews.\n",
        "\n",
        "The **sentiment classification task** consists of predicting the polarity (positive or negative) of a given text.\n",
        "\n",
        "To get the dataset, in your terminal run the following commands:\n",
        "\n",
        "`wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz`\n",
        "\n",
        "`gunzip aclImdb_v1.tar.gz`\n",
        "\n",
        "`tar -xvf aclImdb_v1.tar`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULTILA93WEG8",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizing and term document matrix creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTfp6T5CWEHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH='aclImdb/'               # updated path\n",
        "names = ['neg','pos']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJAAAbNfWELo",
        "colab_type": "code",
        "outputId": "65bc79b0-8696-4044-f9d0-fe8e8a5d205a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls {PATH}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imdbEr.txt  imdb.vocab  README  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyCg7HunWENF",
        "colab_type": "code",
        "outputId": "84d9b716-9b5f-4ced-9659-ea394ccf2b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%ls {PATH}train"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labeledBow.feat  \u001b[0m\u001b[01;34mpos\u001b[0m/    unsupBow.feat  urls_pos.txt\n",
            "\u001b[01;34mneg\u001b[0m/             \u001b[01;34munsup\u001b[0m/  urls_neg.txt   urls_unsup.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM3uCoAjWEOj",
        "colab_type": "code",
        "outputId": "1b556f5b-9685-4f11-b12b-df72c6106e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "%ls {PATH}train/pos | head"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0_9.txt\n",
            "10000_8.txt\n",
            "10001_10.txt\n",
            "10002_7.txt\n",
            "10003_8.txt\n",
            "10004_8.txt\n",
            "10005_7.txt\n",
            "10006_7.txt\n",
            "10007_7.txt\n",
            "10008_7.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MxTXXgTWEQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "5f31a072-2275-4a25-effa-29d654302e94"
      },
      "source": [
        "trn,trn_y = texts_labels_from_folders(f'{PATH}train',names)\n",
        "val,val_y = texts_labels_from_folders(f'{PATH}test',names)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4346a010e6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrn_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts_labels_from_folders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{PATH}train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts_labels_from_folders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{PATH}test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'texts_labels_from_folders' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctj8DsT7WERv",
        "colab_type": "text"
      },
      "source": [
        "Here is the text of the first review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W6OKd5HWETS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xalfKnX_WEU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_y[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwX9NgUbWEW6",
        "colab_type": "text"
      },
      "source": [
        "[`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) converts a collection of text documents to a matrix of token counts (part of `sklearn.feature_extraction.text`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmC3XXQyWEXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "veczr = CountVectorizer(tokenizer=tokenize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9Ia-mOWEYN",
        "colab_type": "text"
      },
      "source": [
        "`fit_transform(trn)` finds the vocabulary in the training set. It also transforms the training set into a term-document matrix. Since we have to apply the *same transformation* to your validation set, the second line uses just the method `transform(val)`. `trn_term_doc` and `val_term_doc` are sparse matrices. `trn_term_doc[i]` represents training document i and it contains a count of words for each document for each word in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5mB-h51WEYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_term_doc = veczr.fit_transform(trn)\n",
        "val_term_doc = veczr.transform(val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZADCSa3WEZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_term_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FFVyn2fWEbe",
        "colab_type": "code",
        "outputId": "95444a49-dfe8-42a9-b820-6f6a25361c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "trn_term_doc[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-01cf02e6d150>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrn_term_doc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trn_term_doc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtyI6hm1WEcj",
        "colab_type": "code",
        "outputId": "7fd68976-6252-4cf2-c7a4-6123726680e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "vocab = veczr.get_feature_names(); vocab[5000:5005]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b79fed4620a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mveczr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5005\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'veczr' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auN1HmKvWEeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w0 = set([o.lower() for o in trn[0].split(' ')]); w0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHr9ixWnWEhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(w0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPS6qGwLWEja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "veczr.vocabulary_['absurd']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi9qk-M7WElL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_term_doc[0,1297]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U__CjfNWEnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_term_doc[0,5000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQp8-kaxWEos",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cOdfRxQWEo_",
        "colab_type": "text"
      },
      "source": [
        "We define the **log-count ratio** $r$ for each word $f$:\n",
        "\n",
        "$r = \\log \\frac{\\text{ratio of feature $f$ in positive documents}}{\\text{ratio of feature $f$ in negative documents}}$\n",
        "\n",
        "where ratio of feature $f$ in positive documents is the number of times a positive document has a feature divided by the number of positive documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AYAEWKzWEpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pr(y_i):\n",
        "    p = x[y==y_i].sum(0)\n",
        "    return (p+1) / ((y==y_i).sum()+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZdaXoLIWEqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=trn_term_doc\n",
        "y=trn_y\n",
        "\n",
        "r = np.log(pr(1)/pr(0))\n",
        "b = np.log((y==1).mean() / (y==0).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OahuCNjWWErI",
        "colab_type": "text"
      },
      "source": [
        "Here is the formula for Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWcUpPenWErU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_preds = val_term_doc @ r.T + b\n",
        "preds = pre_preds.T>0\n",
        "(preds==val_y).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B0v83n1WEst",
        "colab_type": "text"
      },
      "source": [
        "...and binarized Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1pfupAvWEto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=trn_term_doc.sign()\n",
        "r = np.log(pr(1)/pr(0))\n",
        "\n",
        "pre_preds = val_term_doc.sign() @ r.T + b\n",
        "preds = pre_preds.T>0\n",
        "(preds==val_y).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQQ9l0BOWEvt",
        "colab_type": "text"
      },
      "source": [
        "### Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIAL92UpWEwG",
        "colab_type": "text"
      },
      "source": [
        "Here is how we can fit logistic regression where the features are the unigrams."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9obmlgeqWEwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = LogisticRegression(C=1e8, dual=True, solver='liblinear')\n",
        "m.fit(x, y)\n",
        "preds = m.predict(val_term_doc)\n",
        "(preds==val_y).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWrTRoxcWEw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = LogisticRegression(C=1e8, dual=True, solver='liblinear')\n",
        "m.fit(trn_term_doc.sign(), y)\n",
        "preds = m.predict(val_term_doc.sign())\n",
        "(preds==val_y).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fosCYRtcWEyE",
        "colab_type": "text"
      },
      "source": [
        "...and the regularized version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu21tS9sWEyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = LogisticRegression(C=0.1, dual=True, solver='liblinear')\n",
        "m.fit(x, y)\n",
        "preds = m.predict(val_term_doc)\n",
        "(preds==val_y).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXvWGLrOWEze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = LogisticRegression(C=0.1, dual=True, solver='liblinear')\n",
        "m.fit(trn_term_doc.sign(), y)\n",
        "preds = m.predict(val_term_doc.sign())\n",
        "(preds==val_y).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdvuGsaMWE0F",
        "colab_type": "text"
      },
      "source": [
        "### Trigram with NB features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp9ipcQAWE0Q",
        "colab_type": "text"
      },
      "source": [
        "Our next model is a version of logistic regression with Naive Bayes features described [here](https://www.aclweb.org/anthology/P12-2018). For every document we compute binarized features as described above, but this time we use bigrams and trigrams too. Each feature is a log-count ratio. A logistic regression model is then trained to predict sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpvQjNr6WE0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "veczr =  CountVectorizer(ngram_range=(1,3), tokenizer=tokenize, max_features=800000)\n",
        "trn_term_doc = veczr.fit_transform(trn)\n",
        "val_term_doc = veczr.transform(val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AAGsMtSWE1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_term_doc.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMOmpGTkWE3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = veczr.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7saqHPRWE4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab[200000:200005]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6aYV7O0WE7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=trn_y\n",
        "x=trn_term_doc.sign()\n",
        "val_x = val_term_doc.sign()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv1nK5obWE8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r = np.log(pr(1) / pr(0))\n",
        "b = np.log((y==1).mean() / (y==0).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrWu_D_FWE8g",
        "colab_type": "text"
      },
      "source": [
        "Here we fit regularized logistic regression where the features are the trigrams."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu5sZoDwWE8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = LogisticRegression(C=0.1, dual=True)\n",
        "m.fit(x, y);\n",
        "\n",
        "preds = m.predict(val_x)\n",
        "(preds.T==val_y).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3LJjj6DWE9i",
        "colab_type": "text"
      },
      "source": [
        "Here is the $\\text{log-count ratio}$ `r`.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYXIIx3yWE9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r.shape, r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qOtzZ80WE-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.exp(r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-GaI3nrWE-2",
        "colab_type": "text"
      },
      "source": [
        "Here we fit regularized logistic regression where the features are the trigrams' log-count ratios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDNlYmyeWE-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_nb = x.multiply(r)\n",
        "m = LogisticRegression(dual=True, C=0.1, solver='liblinear')   ## Added solver due to FutureWarning\n",
        "m.fit(x_nb, y);\n",
        "\n",
        "val_x_nb = val_x.multiply(r)\n",
        "preds = m.predict(val_x_nb)\n",
        "(preds.T==val_y).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NtPHNs0WE_f",
        "colab_type": "text"
      },
      "source": [
        "## fastai NBSVM++"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXfTiZ44WE_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sl=2000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92m5qBeRWFAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here is how we get a model from a bag of words\n",
        "md = TextClassifierData.from_bow(trn_term_doc, trn_y, val_term_doc, val_y, sl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQYRpVNgWFAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner = md.dotprod_nb_learner()\n",
        "learner.fit(0.02, 1, wds=1e-6, cycle_len=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f3PBwkPWFBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit(0.02, 2, wds=1e-6, cycle_len=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSYvrunTWFCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit(0.02, 2, wds=1e-6, cycle_len=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rin7Uy4LWFGE",
        "colab_type": "text"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP3qM-E5WFGe",
        "colab_type": "text"
      },
      "source": [
        "* Baselines and Bigrams: Simple, Good Sentiment and Topic Classification. Sida Wang and Christopher D. Manning [pdf](https://www.aclweb.org/anthology/P12-2018)"
      ]
    }
  ]
}